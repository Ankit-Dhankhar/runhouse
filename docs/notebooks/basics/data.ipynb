{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Data with Runhouse\n",
        "\n",
        "Runhouse has several abstractions to provide a simple interface for storing, recalling, and moving data between the user’s laptop, remote compute, cloud storage, and specialized storage (e.g. data warehouses). \n",
        "\n",
        "The Folder, Table, and Blob APIs provide least-common-denominator APIs across providers, allowing users to easily specify the actions they want to take on the data without needed to dig into provider-specific APIs."
      ],
      "metadata": {
        "id": "8hjfzpOtNWu6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install Runhouse and Setup Cluster"
      ],
      "metadata": {
        "id": "4LZrV9xLyvM7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install runhouse[aws]"
      ],
      "metadata": {
        "id": "PbOzhZrRyu1f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import runhouse as rh"
      ],
      "metadata": {
        "id": "c4dBSfwHyyDu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "803e4bbf-13e8-4c43-eabf-9e8ec9e519ae"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO | 2023-05-18 21:49:05,914 | No auth token provided, so not using RNS API to save and load configs\n",
            "INFO | 2023-05-18 21:49:06,452 | NumExpr defaulting to 2 threads.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Optionally, login to Runhouse to sync credentials."
      ],
      "metadata": {
        "id": "syFeJZsBy0Dg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!runhouse login"
      ],
      "metadata": {
        "id": "R0CdXUbCyyZB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We also construct a Runhouse cluster object that we will use throughout the tutorial. We won't go in depth about clusters in this tutorial, but you can refer to Getting Started for setup instructions, or the Compute API tutorial for a more in-depth walkthrough of clusters."
      ],
      "metadata": {
        "id": "ij5fCxkZ8213"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cluster = rh.cluster(\n",
        "              name=\"cpu-cluster\",\n",
        "              instance_type=\"CPU:8\",\n",
        "              provider=\"cheapest\",       # \"AWS\", \"GCP\", \"Azure\", \"Lambda\", or \"cheapest\" (default)\n",
        "              autostop_mins=60,          # Optional, defaults to default_autostop_mins; -1 suspends autostop\n",
        "          )\n",
        "cluster.up()"
      ],
      "metadata": {
        "id": "tJz_ouO58zob"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Folders\n",
        "\n",
        "The Runhouse Folder API allows for creating references to folders, and syncing them between local, remote clusters, or file storage (S3, GS, Azure)."
      ],
      "metadata": {
        "id": "IYyhMRnUyjKe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's construct a sample dummy folder locally, that we'll use to demonstrate."
      ],
      "metadata": {
        "id": "M4mGLaYY9g14"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "folder_name = \"sample_folder\"\n",
        "os.makedirs(folder_name, exist_ok=True)\n",
        "\n",
        "for i in range(5):\n",
        "  with open(f'{folder_name}/{i}.txt', 'w') as f:\n",
        "      f.write('i')\n",
        "\n",
        "local_path = f\"{os.getcwd()}/{folder_name}\""
      ],
      "metadata": {
        "id": "91Qnj2g_9f1X"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To create a folder object, use the `rh.folder()` factory function, and use `.to()` to send the folder to a remote cluster."
      ],
      "metadata": {
        "id": "FcOrBx3O8trk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "local_folder = rh.folder(path=f\"{os.getcwd()}/{folder_name}\")\n",
        "cluster_folder = local_folder.to(system=cluster, path=folder_name)\n",
        "\n",
        "cluster.run([f\"ls {folder_name}\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_nRqA7xHzBPF",
        "outputId": "8dcb3c6f-a00d-41e5-99e6-a21e093861dd"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO | 2023-05-18 22:04:19,262 | Creating new file folder if it does not already exist in path: /content/sample_folder\n",
            "INFO | 2023-05-18 22:04:19,270 | Copying folder from file:///content/sample_folder to: cpu-cluster, with path: sample_folder\n",
            "INFO | 2023-05-18 22:04:21,170 | Running command on cpu-cluster: ls sample_folder\n",
            "0.txt\n",
            "1.txt\n",
            "2.txt\n",
            "3.txt\n",
            "4.txt\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0, '0.txt\\n1.txt\\n2.txt\\n3.txt\\n4.txt\\n', '')]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can also send the folder to file storage, such as S3, GS, and Azure."
      ],
      "metadata": {
        "id": "SeRZ-PD9DC5h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "s3_folder = local_folder.to(system=\"s3\")\n",
        "s3_folder.ls(full_paths=False)"
      ],
      "metadata": {
        "id": "O78jStem-f8T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9420142b-b911-456e-b1b2-163ac742882e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO | 2023-05-18 22:04:25,030 | Copying folder from file:///content/sample_folder to: s3, with path: /runhouse-folder/79fe2eef03744148852156a003445885\n",
            "INFO | 2023-05-18 22:04:25,034 | Attempting to load config for /carolineechen/s3 from RNS.\n",
            "INFO | 2023-05-18 22:04:25,275 | No config found in RNS: {'detail': 'Resource does not exist'}\n",
            "INFO | 2023-05-18 22:04:26,717 | Found credentials in shared credentials file: ~/.aws/credentials\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['0.txt', '1.txt', '2.txt', '3.txt', '4.txt']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Similarly, you can send folders from a cluster to file storage, cluster to cluster, or file storage to file storage. These are all done without bouncing the folder off local."
      ],
      "metadata": {
        "id": "-V1lAbB2FKZt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cluster_folder.to(system=another_cluster)  # cluster to cluster\n",
        "cluster_folder.to(system=\"s3\")             # cluster to fs\n",
        "s3_folder.to(system=cluster)               # fs to cluster\n",
        "s3_folder.to(system=\"gs\")                  # fs to fs"
      ],
      "metadata": {
        "id": "hWRVktaeFI2z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tables\n",
        "\n",
        "The Runhouse Table API allows for abstracting tabular data storage, and supports interfaces for HuggingFace, Dask, Pandas, Rapids, and Ray tables (more in progress!).\n",
        "\n",
        "These can be synced and written down to local, remote clusters, or file storage (S3, GS, Azure).\n",
        "\n",
        "Let's step through an example using Pandas tables:"
      ],
      "metadata": {
        "id": "3znmdMxXymU5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.DataFrame(\n",
        "        {\"id\": [1, 2, 3, 4, 5, 6], \"grade\": [\"a\", \"b\", \"b\", \"a\", \"a\", \"e\"]}\n",
        "    )\n",
        "\n",
        "table_name = \"sample_table\"\n",
        "rh_table = rh.table(data=df, name=table_name)\n",
        "print(rh_table.data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PlfZIXCeMnjz",
        "outputId": "f02f8ee9-50dc-4785-f0f7-29f650093f35"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO | 2023-05-18 22:10:14,856 | Attempting to load config for /carolineechen/sample_table from RNS.\n",
            "INFO | 2023-05-18 22:10:15,076 | No config found in RNS: {'detail': 'Resource does not exist'}\n",
            "INFO | 2023-05-18 22:10:15,078 | Attempting to load config for /carolineechen/file from RNS.\n",
            "INFO | 2023-05-18 22:10:15,261 | No config found in RNS: {'detail': 'Resource does not exist'}\n",
            "INFO | 2023-05-18 22:10:15,266 | Creating new file folder if it does not already exist in path: /root/.cache/runhouse/tables/carolineechen/sample_table\n",
            "   id grade\n",
            "0   1     a\n",
            "1   2     b\n",
            "2   3     b\n",
            "3   4     a\n",
            "4   5     a\n",
            "5   6     e\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To sync over and save the table to file storage, like S3, or to a remote cluster:"
      ],
      "metadata": {
        "id": "KxhQqhf-PLh0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rh_table.to(system=\"s3\")\n",
        "rh_table.to(cluster)"
      ],
      "metadata": {
        "id": "uywEtkPlPI4I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8168bd68-129e-46f8-a517-662324207e48"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO | 2023-05-18 22:10:24,487 | Copying folder from file:///root/.cache/runhouse/tables/carolineechen/sample_table to: s3, with path: /runhouse-folder/9215396cea4040c093997f3d5ae48943\n",
            "INFO | 2023-05-18 22:10:24,490 | Attempting to load config for /carolineechen/s3 from RNS.\n",
            "INFO | 2023-05-18 22:10:24,648 | No config found in RNS: {'detail': 'Resource does not exist'}\n",
            "INFO | 2023-05-18 22:10:25,468 | Copying folder from file:///root/.cache/runhouse/tables/carolineechen/sample_table to: cpu-cluster, with path: ~/.cache/runhouse/ed2fd40ca63140408444deca935528ec\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<runhouse.rns.tables.pandas_table.PandasTable at 0x7fc346de6c50>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To stream batches of the table, we reload the table object, but with an iterable `.data` field, using the `rh.table` constructor and passing in the name.\n",
        "\n",
        "Note that you can't directly do this with the original table object, as it's `.data` field is the original `data` passed in, and not necessarily in an iterable format.\n"
      ],
      "metadata": {
        "id": "P68Hrzv_RhH0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "reloaded_table = rh.table(name=table_name)"
      ],
      "metadata": {
        "id": "v9DPNr7hRfIi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batches = reloaded_table.stream(batch_size=2)\n",
        "for _, batch in batches:\n",
        "    print(batch)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZgwQXHJh7QW3",
        "outputId": "4cd3e578-b72a-4b40-84e2-c5ae34c1e715"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2023-05-18 22:13:41,227\tWARNING read_api.py:330 -- ⚠️  The number of blocks in this dataset (0) limits its parallelism to 0 concurrent tasks. This is much less than the number of available CPU slots in the cluster. Use `.repartition(n)` to increase the number of dataset blocks.\n",
            "Parquet Files Sample: : 0it [00:00, ?it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Blobs\n",
        "\n",
        "The Runhouse Blob API represents an entity for storing arbitrary data. Blobs are associated with a system (local, remote, or file storage), and can be written down or synced to systems."
      ],
      "metadata": {
        "id": "41BK2zw8yk7H"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "iLAaOVXPbbFY"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import pickle\n",
        "\n",
        "blob_data = pickle.dumps(json.dumps(list(range(50))))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create local blob and write contents to file\n",
        "local_blob = rh.blob(name=\"local_blob\", data=blob_data).write()\n",
        "print(pickle.loads(local_blob.data))\n",
        "\n",
        "# reload local blob\n",
        "reloaded_blob = rh.blob(name=\"local_blob\")\n",
        "print(pickle.loads(reloaded_blob.fetch()))\n",
        "\n",
        "# to sync the blob to remote or fs\n",
        "local_blob.to(system=cluster)\n",
        "local_blob.to(system=\"s3\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kWz_TF69StEa",
        "outputId": "7cca8d85-0478-4d55-bcda-e3f58e439f9f"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO | 2023-05-18 22:15:54,332 | Attempting to load config for /carolineechen/local_blob from RNS.\n",
            "INFO | 2023-05-18 22:15:54,524 | Attempting to load config for /carolineechen/file from RNS.\n",
            "INFO | 2023-05-18 22:15:54,690 | No config found in RNS: {'detail': 'Resource does not exist'}\n",
            "INFO | 2023-05-18 22:15:54,692 | Creating new file folder if it does not already exist in path: /root/.cache/runhouse/blobs/aa9001761bb14d13bd3545b1f6127a6e/carolineechen\n",
            "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]\n",
            "INFO | 2023-05-18 22:15:54,695 | Attempting to load config for /carolineechen/local_blob from RNS.\n",
            "INFO | 2023-05-18 22:15:54,854 | Attempting to load config for /carolineechen/file from RNS.\n",
            "INFO | 2023-05-18 22:15:55,015 | No config found in RNS: {'detail': 'Resource does not exist'}\n",
            "INFO | 2023-05-18 22:15:55,017 | Creating new file folder if it does not already exist in path: /root/.cache/runhouse/blobs/aa9001761bb14d13bd3545b1f6127a6e/carolineechen\n",
            "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]\n",
            "INFO | 2023-05-18 22:15:55,024 | Copying folder from file:///root/.cache/runhouse/blobs/aa9001761bb14d13bd3545b1f6127a6e/carolineechen to: cpu-cluster, with path: ~/.cache/runhouse/c4ff6d2954124f119932689ff9afa58b\n",
            "INFO | 2023-05-18 22:15:56,856 | Copying folder from file:///root/.cache/runhouse/blobs/aa9001761bb14d13bd3545b1f6127a6e/carolineechen to: s3, with path: /runhouse-folder/932d21850d2a43d8badd485e0d583758\n",
            "INFO | 2023-05-18 22:15:56,861 | Attempting to load config for /carolineechen/s3 from RNS.\n",
            "INFO | 2023-05-18 22:15:57,029 | No config found in RNS: {'detail': 'Resource does not exist'}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<runhouse.rns.blob.Blob at 0x7fc33c268550>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create blob on s3\n",
        "rh.blob(data=blob_data, system=\"s3\").write()\n",
        "\n",
        "# create blob from cluster\n",
        "rh.blob(path=\"path/on/cluster\", system=cluster)"
      ],
      "metadata": {
        "id": "gzAEykn7TLGP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c61b1bf-16f1-48a3-978a-7fc8bb43c506"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO | 2023-05-18 22:16:05,189 | Attempting to load config for /carolineechen/s3 from RNS.\n",
            "INFO | 2023-05-18 22:16:05,352 | No config found in RNS: {'detail': 'Resource does not exist'}\n",
            "INFO | 2023-05-18 22:16:05,354 | Creating new s3 folder if it does not already exist in path: /runhouse-blob/d135efb148b14ae9a05d50d0ba4c7c82\n",
            "INFO | 2023-05-18 22:16:05,374 | Found credentials in shared credentials file: ~/.aws/credentials\n",
            "INFO | 2023-05-18 22:16:05,863 | Creating new ssh folder if it does not already exist in path: path/on\n",
            "INFO | 2023-05-18 22:16:05,919 | Opening SSH connection to 3.93.183.178, port 22\n",
            "INFO | 2023-05-18 22:16:05,951 | [conn=0] Connected to SSH server at 3.93.183.178, port 22\n",
            "INFO | 2023-05-18 22:16:05,952 | [conn=0]   Local address: 172.28.0.12, port 44872\n",
            "INFO | 2023-05-18 22:16:05,955 | [conn=0]   Peer address: 3.93.183.178, port 22\n",
            "INFO | 2023-05-18 22:16:06,083 | [conn=0] Beginning auth for user ubuntu\n",
            "INFO | 2023-05-18 22:16:06,198 | [conn=0] Auth for user ubuntu succeeded\n",
            "INFO | 2023-05-18 22:16:06,201 | [conn=0, chan=0] Requesting new SSH session\n",
            "INFO | 2023-05-18 22:16:06,540 | [conn=0, chan=0]   Subsystem: sftp\n",
            "INFO | 2023-05-18 22:16:06,573 | [conn=0, chan=0] Starting SFTP client\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<runhouse.rns.blob.Blob at 0x7fc33c27a710>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To get the contents from a blob: "
      ],
      "metadata": {
        "id": "X4DA7y3_76l3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "raw_data = local_blob.fetch()\n",
        "pickle.loads(raw_data)  # deserialization"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "FltjM0Qm70cz",
        "outputId": "f867a940-7f6c-4691-d3a7-7c1548fe5f45"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that you understand the basics, feel free to play around with more complicated scenarios! You can also check out our additional API and example usage tutorials on our [docs site](https://runhouse-docs.readthedocs-hosted.com/en/latest/index.html)."
      ],
      "metadata": {
        "id": "-UaQpzxo9FA1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cluster Termination"
      ],
      "metadata": {
        "id": "Rz8GsCvwGnnk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!sky down cpu-cluster\n",
        "# or\n",
        "cluster.teardown()"
      ],
      "metadata": {
        "id": "picvQJ8DGomA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cluster.teardown()"
      ],
      "metadata": {
        "id": "BQjLvOUBWS21",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "049eea20-12ea-4bac-f9be-3c29bb35cf55"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[32m⠹\u001b[0m \u001b[1;36mTerminating \u001b[0m\u001b[1;32mcpu-cluster\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">⠹</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Terminating </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">cpu-cluster</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3Ocos3Ko9WB0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
